---
layout: post
title: "[Glean] Compute Express Link (CXL) Introduction"
description: "This post introduces Compute Express Link (CXL) and its benefits."
categories: [Glean]
tags: [CXL, Compute Express Link, Memory Pooling, Cache Coherency, Protocol]
last_updated: 2024-08-19 11:17:00 GMT+8
excerpt: "This post introduces Compute Express Link (CXL) and its benefits."
redirect_from:
  - /2024/06/26/
---

* Kramdown table of contents
{:toc .toc}

# CXL Introduction

## Introduction[^1]

Compute Express Link (CXL) is a high-speed CPU-to-device and CPU-to-memory interconnect that is designed to accelerate next-generation data center performance. CXL is an open industry standard that is designed to be compatible with existing industry infrastructure, including PCIe, and it is designed to be scalable and flexible to meet the needs of a wide range of applications.

The CXL standard is made up of three protocols that negotiate up within one link that leverages the PCI Express® (PCIe®) electrical layer, including `CXL.io`, `CXL.cache`, and `CXL.memory` (`CXL.mem`). Each of these CXL protocols have separate stacks, multiplexed at the PHY level, ideal for various contexts:

- `CXL.io`: This protocol is carried over from the PCIe protocol layer, with minor tweaks to allow it to be carried concurrently with CXL.mem and CXL.cache. CXL.io is used for link configuration and management tasks, and it can also be used for register reads and writes and large data transfers, such as those used in block storage and traditional networking.
- `CXL.cache`: This CXL protocol delivers cache coherency and extremely low latency. It works for smaller amounts of data (for example, cache lines or individual bytes). The extremely low latency comes from the fact that snoops (processor logic that checks for data changes in the cache) do not require copying data back and forth across the system. Cache coherency means that accelerators have direct access to the same data that the host processors do, enabling faster and more efficient computational offload.
- `CXL.mem`: This protocol provides a low latency access mechanism for memory resident on the CXL link. This capability allows for a number of interesting system architectures, and it inherently comprehends the idea of non-volatile memory. For example, CXL.mem allows pooling memory resources from across different devices so that multiple memory modules can be connected to a server without going through a traditional memory controller and DRAM interface — it gives processors access to shared memory resources.

## Benefits of CXL

- Accelerators: Avoid Copying Data Around the System with Direct Memory Access
- Memory: Pooling Memory Resources Results in Memory Allocations that Fit Your Application

# Reference

[^1]: [How CXL Is Improving Latency in High-Performance Computing](https://www.synopsys.com/blogs/chip-design/cxl-protocol-memory-pooling.html)
+ [Compute Express Link (CXL) Specification](https://www.computeexpresslink.org/)
