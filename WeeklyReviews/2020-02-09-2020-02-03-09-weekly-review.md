---
layout: post
title: "[Weekly Review] 2020/02/03-09"
last_updated: 2020-02-10 18:57:00 GMT+8
description: "the weekly review from 2020/02/03 to 09"
categories: [WeeklyReview]
tags: [Chisel, HPML, HPC, ML4HPC]
excerpt: "This review contains the usage of general data type in Chisel, the basic architecture of NN and the introductions of BNN and the BitFlow algorithm. Also, some materials related to HPC+ML."
redirect_from:
  - /2020/02/09/
---

* Kramdown table of contents
{:toc .toc}
# 2020/02/16-22

This week I read two papers:

1. FPGA/DNN Co-Design: An Efficient Design Methodology for IoT Intelligence on the Edge;
2. BitFlow: Exploiting Vector Parallelism for Binary Neural Networks on CPU;

Also, I continued the survey of `MLforHPC`.

## Chisel Syntax

### Transferring data type in generators

```scala
class ClusterCommonCtrlIO[T1:< Data, T2:< Data](dataType1: T1, dataType2: T2) extends Bundle {
  val inDataSel: T1 = Output(dataType1)
  val outDataSel: T2 = Output(dataType2)
}

class IactClusterIO[T1, T2](dataType1: T1, dataType2: T2, portNum: Int, addrWidth: Int, dataWidth: Int, addrLenWidth: Int, dataLenWidth: Int) extends Bundle {
  val dataPath: Vec[ClusterAddrWithDataCommonIO] = Vec(portNum, new ClusterAddrWithDataCommonIO(addrWidth, dataWidth, addrLenWidth, dataLenWidth)) // output bits and valid
  val ctrlPath = new ClusterCommonCtrlIO[T1, T2](dataType1, dataType2)
}

class IactRouterIO extends Bundle with ClusterConfig {
  val outIOs = new IactClusterIO(UInt(2.W), UInt(2.W), iactPortNum, iactAddrWidth, iactDataWidth, commonLenWidth, commonLenWidth)
  val inIOs: IactClusterIO[UInt, UInt] = Flipped(new IactClusterIO(UInt(2.W), UInt(2.W), iactPortNum, iactAddrWidth, iactDataWidth, commonLenWidth, commonLenWidth))
}

class PEAndRouterIO extends Bundle with ClusterConfig {
  val iactCluster: IactClusterIO[Bool, UInt] = Flipped(new IactClusterIO[Bool, UInt](Bool(), UInt(2.W), iactRouterNum, iactAddrWidth, iactDataWidth, commonLenWidth, commonLenWidth))
}
```

## Neural Network

### [Architecture](https://www.youtube.com/watch?v=oJNHXPs0XDk)

![](https://raw.githubusercontent.com/SingularityKChen/PicUpload/master/img/Snipaste_2020-02-05_12-56-42.png)

### [Overview](https://www.youtube.com/watch?v=aIZtJqtzdQs)

![Autoencoder](https://raw.githubusercontent.com/SingularityKChen/PicUpload/master/img/Snipaste_2020-02-05_13-00-16.png)

### [Types of ML](https://www.youtube.com/watch?v=YlGEQyEM_a8)

![Types of Machine Learning](https://raw.githubusercontent.com/SingularityKChen/PicUpload/master/img/20200206191447Types%20of%20Machine%20Learning.png)

## HPC + AI

### HPC + Ai: Machine Learning Models in Scientific Computing

[This YouTube video](https://www.youtube.com/watch?v=SV3cnWf39kc) and [see the slide here](http://www.hpcadvisorycouncil.com/events/2019/stanford-workshop/pdf/DayTwo_Friday_15Feb_2019/S_Oberlin_HPC+AI_Friday_02152019.pdf).

![INGREDIENTS: BIG DATA](https://raw.githubusercontent.com/SingularityKChen/PicUpload/master/img/202002051919018%20INGREDIENTS%3A%20BIG%20DATA.png)

![](https://raw.githubusercontent.com/SingularityKChen/PicUpload/master/img/20200205192524.png)

![MIIDAPS-AI](https://raw.githubusercontent.com/SingularityKChen/PicUpload/master/img/20200205213247MIIDAPS-AI.png)

![THE PROMISE OF HPC+AI](https://raw.githubusercontent.com/SingularityKChen/PicUpload/master/img/20200205213333THE%20PROMISE%20OF%20HPC%2BAI.png)

### [How machine learning can improve HPC applications](https://blog.surf.nl/en/how-machine-learning-can-improve-hpc-applications/)

Traditionally, the main workloads run on a supercomputer consists of  various forms of numerical simulations, such as weather modelling,  molecular dynamics, etc.

Early results indicate that these models, that combine machine learning  and traditional simulation, can improve accuracy, accelerate time to  solution and significantly reduce costs.

And in that context, is it a pre- or post-processing step to help filter and understand the input data or ultimate simulation results, or is it  something that is poised to (partly) replace the decades-old codes that  comprise many HPC workloads?

Consequently, early research projects have shown that machine learning  often requires orders of magnitude fewer resources to unlock problems  that have often been beyond the grasp of traditional techniques. Since  performance increases in traditional high-performance computing (HPC)  have been highly dependent on Mooreâ€™s Law, this approach presents a  promising avenue to explore.

Use of machine learning to increase the resolution of a traditional  numerical simulation. The traditional simulation would still be used for simulation at the conventional grid size, while the machine learning  model could use that as input to make predictions at an increased  resolution.

![Use of machine learning to increase the resolution of a traditional  numerical simulation. The traditional simulation would still be used for simulation at the conventional grid size, while the machine learning  model could use that as input to make predictions at an increased  resolution.](https://blog.surf.nl/wp-content/uploads/2018/07/Afbeelding1.png)

### [Supercomputers and Machine Learning: A Perfect Match - insideBIGDATA](https://insidebigdata.com/2019/11/27/supercomputers-and-machine-learning-a-perfect-match/)

Unlike traditional computers, supercomputers use parallel processing.  This multitasking capability enables supercomputers to process  calculations at a much faster rate. 

#### What Is High-Performance Computing and How Does it Work?

HPC architectures typically consist of three components: the Compute Cluster, the Network and Data Storage. 

#### To Cloud or Not to Cloud?

Big data is too big to be processed using traditional database  techniques. The cloud provides the scalability and flexibility required  to process such large data sets. Hardware virtualization, for example,  enables organizations to scale easily. This is useful for data-intensive applications. 

However, there are some considerations when moving big data operations  to the cloud. **Such large and varied amounts of data can be problematic  to synch between on-premises data centers and the cloud.** This can affect the I/O performance in the cloud environment.

Scientists are using machine learning techniques to improve the auto-tuning of exascale applications.

High-performance computing provides unique advantages for machine learning models, including:

- Large amounts of floating-point operations (FLOPS)
- Low-latency
- Parallel I/O


